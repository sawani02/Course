{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border:none;color:#333;background-color:#333;\" />\n",
    "<img style=\" float:right; display:inline\" src=\"http://opencloud.utsa.edu/wp-content/themes/utsa-oci/images/logo.png\"/>\n",
    "\n",
    "### **University of Texas at San Antonio** \n",
    "<br/>\n",
    "<br/>\n",
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 2.5em;\"> **Open Cloud Institute** </span>\n",
    "\n",
    "<hr style=\"height:3px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning/BigData EE-6973-001-Fall-2016\n",
    "\n",
    "<br/>\n",
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.5em;\"> **Paul Rad, Ph.D.** </span>  \n",
    "\n",
    "\n",
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.5em;\"> **Ali Miraftab, Research Fellow** </span>\n",
    "  \n",
    "\n",
    "<hr style=\"height:1.5px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:1.5px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 2em;\"> **Deep Neural Network for Retinal Disease** </span>  \n",
    "<br/>\n",
    "<br/>\n",
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.6em;\"> Mitha Ann Philip, Paul Rad </span>  \n",
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.4em;\"> *Open Cloud Institute, University of Texas at San Antonio, San Antonio, Texas, USA* </span>  \n",
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.4em;\"> {jrb468, Paul.Rad}@utsa.edu </span>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.5em;\"> **Project Definition:** </span> <span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.3em;\"> The retinal blood vessels in our eye are good references for evaluating / monitoring human health.  For correct and early diagnose of the disease, accurate segmentation of the retinal vessel is required to facilitate detection of various pathological modifications. Retinal imaging requires a robust technique that can accurately segment down the entire retinal blood vessel information even in varied imaging conditions such as lower contrast, non-uniform illumination and images with significant changes on the retinal image.\n",
    "\n",
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.3em;\">A tensorflow implementation of deep learning neural network based vessel segmentation method could be a robust technique towards identifying the retinal blood vessels from such retinal images efficiently. In this automatic retinal vessel extraction technique, the first approach could be an image enhancement step that could prepare the input for feature extraction / detection purpose. This can then be followed by directing the input to a convolutional neural network to extract the retinal vessel information and use it for disease classification. \t\n",
    " </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.5em;\"> **Outcome:** </span> <span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.3em;\"> Segmented Retinal fundus image and disease classification for diabetic retinopathy. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.5em;\"> **Dataset:** </span> <span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.3em;\"> \n",
    "The image data can be found in the following links:\n",
    "\n",
    "•\tDRIVE Database: http://www.isi.uu.nl/Research/Databases/DRIVE/. \n",
    "\n",
    "•\tSTARE Databse: http://cecas.clemson.edu/~ahoover/stare/ \n",
    "\n",
    "•\t CHASE Database: https://blogs.kingston.ac.uk/retinal/chasedb1/\n",
    "\n",
    "</span> \n",
    "\n",
    "[1]: http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-8/faceimages/faces/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "<img style=\" float:left; display:inline\" src=\"\" width=\"160\" height=\"90\"/>\n",
    "<img style=\" float:left; display:inline\" src=\"https://upload.wikimedia.org/wikipedia/en/b/b3/HealthyEyeFundus.jpg\" width=\"160\" height=\"90\"/>\n",
    "<img style=\" float:left; display:inline\" src=\"https://www.researchgate.net/profile/Hamid_Pourreza/publication/249318338/figure/fig1/AS:298261698105344@1448122538020/Fig-1-Sample-images-of-DRIVE-database-Note-the-high-color-and-illumination-variation.png\" width=\"360\" height=\"290\"/>\n",
    "<img style=\" float:left; display:inline\" src=\"http://static.framar.bg/snimki/zabolyavaniya//serozno_otlepwane_na_retina.jpg\" width=\"160\" height=\"90\"/>\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[1]: Automated characterization of blood vessels as arteries and veins in retinal imagesv\n",
    "\n",
    "[2]: http://static.framar.bg/snimki/zabolyavaniya//serozno_otlepwane_na_retina.jpg\n",
    "\n",
    "[3]: https://upload.wikimedia.org/wikipedia/en/b/b3/HealthyEyeFundus.jpg\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
