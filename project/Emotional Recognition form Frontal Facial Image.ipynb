{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:3px;border:none;color:#333;background-color:#333;\" />\n",
    "<img style=\" float:right; display:inline\" src=\"http://opencloud.utsa.edu/wp-content/themes/utsa-oci/images/logo.png\"/>\n",
    "\n",
    "### **University of Texas at San Antonio** \n",
    "<br/>\n",
    "<br/>\n",
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 2.5em;\"> **Open Cloud Institute** </span>\n",
    "\n",
    "<hr style=\"height:3px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Machine Learning/BigData EE-6973-001-Fall-2016\n",
    "\n",
    "<br/>\n",
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.5em;\"> **Paul Rad, Ph.D.** </span>  \n",
    "\n",
    "\n",
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.5em;\"> **Ali Miraftab, Research Fellow** </span>\n",
    "  \n",
    "\n",
    "<hr style=\"height:1.5px;border:none;color:#333;background-color:#333;\" />\n",
    "<hr style=\"height:1.5px;border:none;color:#333;background-color:#333;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 2em;\"> **Emotional Detection of Face Image** </span>  \n",
    "<br/>\n",
    "<br/>\n",
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.6em;\"> Alex Torres, Hao Yan </span>  \n",
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.4em;\"> *Electrical & Computer Engineering, University of Texas at San Antonio, San Antonio, Texas, USA* </span>  \n",
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.4em;\"> {alexdtorres91, haoyan123}@gmail.com </span>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.5em;\"> **Project Definition:** </span> <span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.3em;\"> Using deep neural network models,  classification of camera images of faces of various emotion. The dataset includes images of 7 different emotion expression of face </span>\n",
    "\n",
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.3em;\"> <Strong>train.csv</Strong> contains two columns, \"emotion\" and \"pixels\". The \"emotion\" column contains a numeric code ranging from 0 to 6, inclusive, for the emotion that is present in the image. The \"pixels\" column contains a string of pixel intensities for the image. The contents of this string are space-separated pixel values in row major order. <Strong>test.csv</Strong> contains only the \"pixels\" column and your task is to predict the emotion column.\n",
    "The training set consists of 28,709 examples. The public test set used for the leaderboard consists of 3,589 examples. The final test set, which was used to determine the error rate of models.\n",
    "</span>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.5em;\"> **Outcome:** </span> <span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.3em;\"> Applying convolutional neural network to identify the emotion from the face image </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.5em;\"> **Dataset:** </span> <span style=\"color:#000; font-family: 'Bebas Neue'; font-size: 1.3em;\"> The image data can be found in https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data. The data consists of 48x48 pixel grayscale images of faces. The faces have been automatically registered so that the face is more or less centered and occupies about the same amount of space in each image. The task is to categorize each face based on the emotion shown in the facial expression in to one of seven categories (0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral).</span> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div style=\"width:830; background-color:white; height:410px; overflow:scroll; overflow-x: scroll;overflow-y: hidden;\">\n",
    "\n",
    "\n",
    "<img style=\" float:left; display:inline\" src=\"http://www.pitt.edu/~emotion/images/um-spread1.jpg\" width=\"882\" height=\"520\"/>\n",
    "\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
